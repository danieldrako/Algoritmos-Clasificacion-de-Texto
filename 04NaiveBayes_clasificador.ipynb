{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRNkpnn+k6tRA3DbsauZAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieldrako/Algoritmos-Clasificacion-de-Texto/blob/main/04NaiveBayes_clasificador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wr0FeteybH1N"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSHovwBR1ZfA"
      },
      "source": [
        "## Preparación del corpus de emails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8P_ve0L0Gyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56ad8c3-2124-4828-e7a7-fba55d18a1f5"
      },
      "source": [
        "!git clone https://github.com/pachocamacho1990/datasets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Total 39 (delta 0), reused 0 (delta 0), pack-reused 39\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFrqDzfu04pJ"
      },
      "source": [
        "! unzip datasets/email/plaintext/corpus1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('corpus1/spam')"
      ],
      "metadata": {
        "id": "IEpuYaofbqnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJTtSZto1jC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fbedbcd-6710-411b-ba21-87d68c56988c"
      },
      "source": [
        "data = []\n",
        "clases = []\n",
        "#lectura de spam data\n",
        "for file in os.listdir('corpus1/spam'):\n",
        "  with open('corpus1/spam/'+file, encoding='latin-1') as f:\n",
        "    data.append(f.read())\n",
        "    clases.append('spam')\n",
        "#lectura de ham data\n",
        "for file in os.listdir('corpus1/ham'):\n",
        "  with open('corpus1/ham/'+file, encoding='latin-1') as f:\n",
        "    data.append(f.read())\n",
        "    clases.append('ham')\n",
        "len(data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5172"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NOb61Ik7MI-"
      },
      "source": [
        "## Construcción de modelo Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXXlUjrJ7DjR"
      },
      "source": [
        "### Tokenizador de Spacy\n",
        "\n",
        "* Documentación: https://spacy.io/api/tokenizer\n",
        "* ¿Cómo funciona el tokenizador? https://spacy.io/usage/linguistic-features#how-tokenizer-works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePmKCQpw4cqK"
      },
      "source": [
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "tokenizer = Tokenizer(nlp.vocab)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF1cGmZ293OA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b227e1c-a8c3-4f36-b755-c354c2f51211"
      },
      "source": [
        "print([t.text for t in tokenizer(data[0])])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Subject:', 'more', 'money', 'now', '\\n', 'stop', 'making', 'other', 'people', 'rich', '\\n', 'run', 'your', 'own', 'business', 'and', 'make', 'your', 'own', 'rules', '\\n', 'you', 'can', 'even', 'work', 'from', 'home', '-', 'no', 'prior', 'knowledge', 'needed', '\\n', 'the', 'cas?no', 'industry', 'has', 'has', '10', 'billion', 'dollars', '/', 'year', 'for', 'the', 'taking', '\\n', 'want', 'in', 'on', 'this', '?', '\\n', 'call', '1', '-', '877', '-', '467', '-', '2636', 'ext', ':', '213', 'for', 'more', 'info', '.', '\\n', 'bilharziasis', 'biracial', 'coy', 'addition', 'emotional', 'circus', 'rpm', '\\n', 'verdict', 'pedestal', 'appanage', 'cranford', 'cedar', 'deterred', 'hoop', '\\n', 'dolan', 'golf', 'regis', 'burette', 'honey', 'blood', 'manage', '\\n', 'sanskrit', 'puccini', 'spitfire', 'megohm', 'distinguish', 'deadwood', 'syrinx', '\\n', 'encroach', 'now', 'advise', 'calcify', 'nutritive', 'mouthful', 'scoop', '\\n', 'your', 'tomorrow', 'dandelion', 'interfere', 'misanthrope', 'centerline', 'canister', '\\n', 'fresh', 'repetition', 'rheum', 'conjuncture', 'digit', 'punster', 'gosling', '\\n', 'seedling', 'event', 'hadrian', 'doreen', 'coercive', 'curran', 'smatter', '\\n', 'partial', 'clark', 'illegible', 'characteristic', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4i6IQGx7Tul"
      },
      "source": [
        "### Clase principal para el algoritmo\n",
        "\n",
        "Recuerda que la clase más probable viene dada por (en espacio de cómputo logarítmico): \n",
        "\n",
        "\n",
        "$$\\hat{c} = {\\arg \\max}_{(c)}\\log{P(c)}\n",
        " +\\sum_{i=1}^n\n",
        "\\log{ P(f_i \\vert c)}\n",
        "$$\n",
        "\n",
        "Donde, para evitar casos atípicos, usaremos el suavizado de Laplace así:\n",
        "\n",
        "$$\n",
        "P(f_i \\vert c) = \\frac{C(f_i, c)+1}{C(c) + \\vert V \\vert}\n",
        "$$\n",
        "\n",
        "siendo $\\vert V \\vert$ la longitud del vocabulario de nuestro conjunto de entrenamiento. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTgbTusfyPHW"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NaiveBayesClassifier():\n",
        "  nlp = English()\n",
        "  tokenizer = Tokenizer(nlp.vocab)\n",
        "  \n",
        "  def tokenize(self, doc):\n",
        "    return  [t.text.lower() for t in tokenizer(doc)]\n",
        "\n",
        "  def word_counts(self, words):\n",
        "    wordCount = {}\n",
        "    for w in words: \n",
        "      if w in wordCount.keys():\n",
        "        wordCount[w] += 1\n",
        "      else:\n",
        "        wordCount[w] = 1\n",
        "    return wordCount\n",
        "\n",
        "  def fit(self, data, clases):\n",
        "    n = len(data)\n",
        "    self.unique_clases = set(clases)\n",
        "    self.vocab = set()\n",
        "    self.classCount = {} #C(c)\n",
        "    self.log_classPriorProb = {} #log (P(c))\n",
        "    self.wordConditionalCounts = {} #C(w|c)\n",
        "    #conteos de clases\n",
        "    for c in clases:\n",
        "      if c in self.classCount.keys():\n",
        "        self.classCount[c] += 1\n",
        "      else:\n",
        "        self.classCount[c] = 1\n",
        "    # calculo de P(c)\n",
        "    for c in self.classCount.keys():\n",
        "      self.log_classPriorProb[c] = math.log(self.classCount[c]/n)\n",
        "      self.wordConditionalCounts[c] = {}\n",
        "    # calculo de C(w|c)\n",
        "    for text, c in zip(data, clases):\n",
        "      counts = self.word_counts(self.tokenize(text))\n",
        "      for word, count in counts.items():\n",
        "        if word not in self.vocab:\n",
        "          self.vocab.add(word)\n",
        "        if word not in self.wordConditionalCounts[c]:\n",
        "          self.wordConditionalCounts[c][word] = 0.0\n",
        "        self.wordConditionalCounts[c][word] += count\n",
        "\n",
        "  def predict(self, data):\n",
        "    results = []\n",
        "    for text in data:\n",
        "      words = set(self.tokenize(text))\n",
        "      scoreProb = {}\n",
        "      for word in words: \n",
        "        if word not in self.vocab: continue #ignoramos palabras nuevas\n",
        "        #suavizado Laplaciano para P(w|c)\n",
        "        for c in self.unique_clases:\n",
        "          log_wordClassProb = math.log(\n",
        "              (self.wordConditionalCounts[c].get(word, 0.0)+1)/(self.classCount[c]+len(self.vocab)))\n",
        "          scoreProb[c] = scoreProb.get(c, self.log_classPriorProb[c]) + log_wordClassProb\n",
        "      arg_maxprob = np.argmax(np.array(list(scoreProb.values())))\n",
        "      results.append(list(scoreProb.keys())[arg_maxprob])\n",
        "    return results\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE9Aus71bdUx"
      },
      "source": [
        "### Utilidades de Scikit Learn\n",
        "* `train_test_split`: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "* `accuracy_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
        "\n",
        "* `precision_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
        "\n",
        "* `recall_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m95539uQZaDZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "data_train, data_test, clases_train, clases_test = train_test_split(data, clases, test_size=0.10, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qrb-42APpHM"
      },
      "source": [
        "classifier = NaiveBayesClassifier()\n",
        "classifier.fit(data_train, clases_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdzx7-5xXJfD"
      },
      "source": [
        "clases_predict = classifier.predict(data_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0whDaiFwayf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6df75c-c69c-46a1-84b7-462061bef0f0"
      },
      "source": [
        "accuracy_score(clases_test, clases_predict)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8359073359073359"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQM3QjN1dlIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e2356b-5acd-4493-b7c6-23cc45c23785"
      },
      "source": [
        "precision_score(clases_test, clases_predict, average=None, zero_division=1)\n",
        "# de todo lo que es correo legitimo el 81% lo es y de todo lo que yo predije como spam el 100% lo es "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.81026786, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiWQMX0Jdmnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ae01b9-4207-4a5d-a7da-21da2b5c5b6d"
      },
      "source": [
        "recall_score(clases_test, clases_predict, average=None, zero_division=1)\n",
        "#lo que en el dataset realmente es correo valido, logre capturar el 100%"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.       , 0.4516129])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FzK1BgVzjwOA"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}